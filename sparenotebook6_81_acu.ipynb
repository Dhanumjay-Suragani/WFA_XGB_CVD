{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20dcbab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main\\wfa_xgb_cvd_prediction\n",
      "\n",
      "Parents of CWD:\n",
      "0: c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main\n",
      "1: c:\\Users\\dhanu\\OneDrive\\Desktop\n",
      "2: c:\\Users\\dhanu\\OneDrive\n",
      "3: c:\\Users\\dhanu\n",
      "4: c:\\Users\n",
      "5: c:\\\n",
      "\n",
      "Initial sys.path (first 5):\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Programs\\Python\\Python311\\python311.zip\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Programs\\Python\\Python311\\DLLs\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\n",
      "C:\\Users\\dhanu\\AppData\\Local\\Programs\\Python\\Python311\n",
      "c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main\\wfa_xgb_cvd_prediction\\wfa_xgb_env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "\n",
    "cwd = Path.cwd()\n",
    "print(\"\\nParents of CWD:\")\n",
    "for i, p in enumerate(cwd.parents):\n",
    "    print(f\"{i}: {p}\")\n",
    "\n",
    "print(\"\\nInitial sys.path (first 5):\")\n",
    "for p in sys.path[:5]:\n",
    "    print(p)\n",
    "# Resolve project root: wfa_xgb_cvd_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f553f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'src' not found at c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m PROJECT_ROOT = Path.cwd().parents[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# ✅ VERIFIED CORRECT\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).exists():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROJECT_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(PROJECT_ROOT))\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Project root set to:\u001b[39m\u001b[33m\"\u001b[39m, PROJECT_ROOT)\n",
      "\u001b[31mRuntimeError\u001b[39m: 'src' not found at c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main"
     ]
    }
   ],
   "source": [
    "# ---- Project path fix (DO NOT SKIP) ----\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parents[0]  # ✅ VERIFIED CORRECT\n",
    "\n",
    "if not (PROJECT_ROOT / \"src\").exists():\n",
    "    raise RuntimeError(f\"'src' not found at {PROJECT_ROOT}\")\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"✅ Project root set to:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede56224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.paths import (\n",
    "    HEART_VERIFIED_CSV,\n",
    "    BASELINE_RESULTS_CSV,\n",
    "    WFA_FEATURE_WEIGHTS_CSV,\n",
    "    FEATURE_AUGMENTED_WEIGHTS_CSV,\n",
    "    BASELINE_MODEL_PKL,\n",
    "    WFA_XGB_MODEL_JSON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbe608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ce025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded\n",
      "(1238, 11) (272, 11)\n"
     ]
    }
   ],
   "source": [
    "from src.data.load_data import load_dataset\n",
    "from src.data.split_data import split_data\n",
    "\n",
    "X, y = load_dataset(\n",
    "    PROJECT_ROOT / \"data\" / \"processed\" / \"heart_Verified.csv\",\n",
    "    target_col=\"target\"\n",
    ")\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
    "\n",
    "print(\"✅ Data loaded\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "# Compute sample weights based on predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b690b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature weights loaded: (11,)\n"
     ]
    }
   ],
   "source": [
    "WFA_WEIGHTS_PATH = PROJECT_ROOT / \"notebooks\" / \"experiments\" / \"wfa_feature_weights.csv\"\n",
    "\n",
    "if not WFA_WEIGHTS_PATH.exists():\n",
    "    raise FileNotFoundError(f\"WFA weights not found at {WFA_WEIGHTS_PATH}\")\n",
    "\n",
    "feature_weights = pd.read_csv(\n",
    "    WFA_WEIGHTS_PATH,\n",
    "    index_col=0\n",
    ").squeeze()\n",
    "\n",
    "# align order\n",
    "feature_weights = feature_weights.loc[X_train.columns]\n",
    "\n",
    "print(\"✅ Feature weights loaded:\", feature_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66153926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WFA-XGB (safe) trained\n"
     ]
    }
   ],
   "source": [
    "wfa_xgb_safe = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply feature weighting consistently\n",
    "X_train_w = X_train * feature_weights\n",
    "X_test_w  = X_test  * feature_weights\n",
    "\n",
    "wfa_xgb_safe.fit(X_train_w, y_train)\n",
    "\n",
    "print(\"✅ WFA-XGB (safe) trained\")\n",
    "# Predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909a472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability range: 0.0036155272 → 0.990346\n",
      "Unique probs: 267\n"
     ]
    }
   ],
   "source": [
    "y_prob = wfa_xgb_safe.predict_proba(X_test_w)[:, 1]\n",
    "\n",
    "print(\"Probability range:\", y_prob.min(), \"→\", y_prob.max())\n",
    "print(\"Unique probs:\", len(np.unique(np.round(y_prob, 4))))\n",
    "# Compute sample weights based on predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72615793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WFA-XGB (safe)</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  threshold  accuracy  precision    recall  f1_score  \\\n",
       "0  WFA-XGB (safe)        0.5    0.8125   0.839695  0.785714  0.811808   \n",
       "\n",
       "    roc_auc  \n",
       "0  0.887554  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "wfa_results = {\n",
    "    \"model\": \"WFA-XGB (safe)\",\n",
    "    \"threshold\": 0.5,\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_prob)\n",
    "}\n",
    "\n",
    "wfa_df = pd.DataFrame([wfa_results])\n",
    "wfa_df\n",
    "# Compute sample weights based on predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002bc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.828767</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.839695</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy  precision    recall  f1_score   roc_auc\n",
       "4       0.30  0.816176   0.788462  0.878571  0.831081  0.887554\n",
       "5       0.35  0.816176   0.796053  0.864286  0.828767  0.887554\n",
       "6       0.40  0.823529   0.828571  0.828571  0.828571  0.887554\n",
       "7       0.45  0.816176   0.830882  0.807143  0.818841  0.887554\n",
       "8       0.50  0.812500   0.839695  0.785714  0.811808  0.887554"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.linspace(0.1, 0.9, 17)\n",
    "records = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_hat = (y_prob >= t).astype(int)\n",
    "\n",
    "    records.append({\n",
    "        \"threshold\": t,\n",
    "        \"accuracy\": accuracy_score(y_test, y_hat),\n",
    "        \"precision\": precision_score(y_test, y_hat, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_hat),\n",
    "        \"f1_score\": f1_score(y_test, y_hat),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_prob)  # invariant to threshold\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(records)\n",
    "threshold_df.sort_values(\"f1_score\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362c1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WFA-XGB (threshold optimized)</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.887554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  threshold  accuracy  precision    recall  \\\n",
       "0  WFA-XGB (threshold optimized)        0.3  0.816176   0.788462  0.878571   \n",
       "\n",
       "   f1_score   roc_auc  \n",
       "0  0.831081  0.887554  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = threshold_df.sort_values(\"f1_score\", ascending=False).iloc[0]\n",
    "\n",
    "optimized_results = {\n",
    "    \"model\": \"WFA-XGB (threshold optimized)\",\n",
    "    **best.to_dict()\n",
    "}\n",
    "\n",
    "optimized_df = pd.DataFrame([optimized_results])\n",
    "optimized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evaluation saved to: c:\\Users\\dhanu\\OneDrive\\Desktop\\CD_Main\\wfa_xgb_cvd_prediction\\notebooks\\experiments\\wfa_evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = PROJECT_ROOT / \"notebooks\" / \"experiments\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "eval_path = OUTPUT_DIR / \"wfa_evaluation_results.csv\"\n",
    "optimized_df.to_csv(eval_path, index=False)\n",
    "\n",
    "print(\"✅ Evaluation saved to:\", eval_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wfa_xgb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
